---
title: "preliminaryTasks"
output: html_document
---
```{r}
library(tidyverse)
library(tidytext)
library(textstem)
library(rvest)
library(qdapRegex)
require(stopwords)
require(tokenizers
```




## Preliminary Task 1: Augmenting HTML to include header
```{r}
require(tidyverse)
require(tidytext)
require(textstem)
require(rvest)
require(qdapRegex)
require(stopwords)
require(tokenizers)
```

```{r}
# --- parse html: paragraphs + headers, with optional header weighting ---
parse_fn <- function(.html, header_weight = 2L){
  doc <- read_html(.html)

  # grab paragraphs and headers
  p_txt <- doc %>% html_elements('p') %>% html_text2()
  h_txt <- doc %>% html_elements('h1, h2, h3, h4, h5, h6') %>% html_text2()

  # optional weighting: repeat header text
  if (length(h_txt) && header_weight > 1) {
    h_txt <- rep(h_txt, each = header_weight)
  }

  # merge then clean
  paste(c(p_txt, h_txt), collapse = " ") %>%
    rm_url() %>%
    rm_email() %>%
    str_remove_all("'") %>%
    str_replace_all(paste(c("\n","[[:punct:]]","nbsp","[[:digit:]]","[[:symbol:]]"), collapse="|"), " ") %>%
    str_replace_all("([a-z])([A-Z])", "\\1 \\2") %>%
    tolower() %>%
    str_replace_all("\\s+", " ") %>%
    str_squish()
}
```

```{r}
# apply to claims data; choose header_weight (try 1 = no weight; 2 = mild)
parse_data <- function(.df, header_weight = 2L){
  .df %>%
    filter(str_detect(text_tmp, "<!")) %>%
    rowwise() %>%
    mutate(text_clean = parse_fn(text_tmp, header_weight = header_weight)) %>%
    unnest(text_clean)
}

# tokenization + tf-idf (unchanged)
nlp_fn <- function(parse_data.out){
  parse_data.out %>%
    unnest_tokens(output = token,
                  input = text_clean,
                  token = "words",
                  stopwords = str_remove_all(stop_words$word, "[[:punct:]]")) %>%
    mutate(token.lem = lemmatize_words(token)) %>%
    filter(str_length(token.lem) > 2) %>%
    count(.id, bclass, token.lem, name = "n") %>%
    bind_tf_idf(term = token.lem, document = .id, n = n) %>%
    pivot_wider(id_cols = c(".id","bclass"),
                names_from = "token.lem",
                values_from = "tf_idf",
                values_fill = 0)
}

```

